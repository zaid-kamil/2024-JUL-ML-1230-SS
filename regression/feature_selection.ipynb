{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/digipodium/Datasets/main/regression/kc_house_data.csv'\n",
    "df = pd.read_csv(url, parse_dates=['date'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['id', 'date', 'price'], axis=1)\n",
    "y = df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression, VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector_1 = VarianceThreshold(threshold=0.1)\n",
    "X_selected = selector_1.fit_transform(X)\n",
    "X_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected columns\n",
    "X.columns[selector_1.get_support()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns dropped\n",
    "X.columns[~selector_1.get_support()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector_2 = SelectKBest(f_regression, k=10)\n",
    "X_selected = selector_2.fit_transform(X, y)\n",
    "X_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected columns\n",
    "X.columns[selector_2.get_support()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropped columns\n",
    "X.columns[~selector_2.get_support()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2, suppress=True)\n",
    "selector_2.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('selector', SelectKBest(f_regression, k=10)),\n",
    "    ('regressor', DecisionTreeRegressor(max_depth=10))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('selector', VarianceThreshold(threshold=0.2)),\n",
    "    ('regressor', DecisionTreeRegressor(max_depth=10))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "model_1.fit(Xtrain, ytrain)\n",
    "_ = model_2.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model 1 Score\", model_1.score(Xtest, ytest))   \n",
    "print(\"Model 2 Score\", model_2.score(Xtest, ytest))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F regression columns: \", X.columns[model_1['selector'].get_support()].to_list())\n",
    "print(\"Variance Threshold columns: \", X.columns[model_2['selector'].get_support()].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skewness = y.skew()# it should be close to 0\n",
    "fig, ax = plt.subplots(figsize=(10, 5)) \n",
    "sns.histplot(y, kde=True,ax=ax)\n",
    "ax.text(x=2*10**6, y=800, s=f'Skewness: {skewness}', fontsize=16,)\n",
    "ax.text(x=2*10**6, y=700, s=f'data is very skewed', fontsize=12,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt = np.log1p(y) # log transform that reduces skewness\n",
    "skewness = yt.skew()\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "sns.histplot(yt, kde=True, ax=ax)\n",
    "ax.text(x=14, y=800, s=f'Skewness: {skewness:.2f}', fontsize=16,)\n",
    "ax.text(x=14, y=700, s=f'data is less skewed', fontsize=12,)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the final model\n",
    "model_3 = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('selector', VarianceThreshold(threshold=0.2)),\n",
    "    ('regressor', DecisionTreeRegressor(max_depth=10))\n",
    "])\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, yt, test_size=0.2, random_state=0)\n",
    "model_3.fit(Xtrain, ytrain)\n",
    "print(\"Model 3 Score\", model_3.score(Xtest, ytest))\n",
    "ypred = model_3.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Actual': np.expm1(ytest),\n",
    "    'Predicted': np.expm1(ypred), # expm1 is the inverse of log1p\n",
    "})\n",
    "\n",
    "sns.histplot(results['Actual'], kde=True, color='b', label='Actual', alpha=0.5)\n",
    "sns.histplot(results['Predicted'], kde=True, color='r', label='Predicted', alpha=0.5)\n",
    "plt.xlim([0, 2000000])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
